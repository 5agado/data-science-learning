{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Load-Network\" data-toc-modified-id=\"Load-Network-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Load Network</a></span></li><li><span><a href=\"#Project\" data-toc-modified-id=\"Project-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Project</a></span></li><li><span><a href=\"#Encode\" data-toc-modified-id=\"Encode-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Encode</a></span></li><li><span><a href=\"#Generate-Images\" data-toc-modified-id=\"Generate-Images-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Generate Images</a></span><ul class=\"toc-item\"><li><span><a href=\"#generate-some-random-samples-and-save-to-disk\" data-toc-modified-id=\"generate-some-random-samples-and-save-to-disk-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>generate some random samples and save to disk</a></span></li></ul></li><li><span><a href=\"#Projected-Latent-Initialization\" data-toc-modified-id=\"Projected-Latent-Initialization-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Projected Latent Initialization</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-latents-from-other-network-and-generate-with-current\" data-toc-modified-id=\"Load-latents-from-other-network-and-generate-with-current-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Load latents from other network and generate with current</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project/embed real images into StyleGANv2 latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import imageio\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# ffmpeg installation location, for creating videos\n",
    "plt.rcParams['animation.ffmpeg_path'] = str(Path.home() / \"Documents/dev_tools/ffmpeg-20190623-ffa64a4-win64-static/bin/ffmpeg.exe\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# StyleGAN Utils\n",
    "from stylegan_utils import load_network, gen_image_fun, synth_image_fun, create_video, map_latents\n",
    "\n",
    "import dnnlib\n",
    "import dataset_tool\n",
    "import run_projector\n",
    "import projector\n",
    "import training.dataset\n",
    "import training.misc\n",
    "\n",
    "# Specific of encoder repos, comment out if not needed\n",
    "#from encoder.perceptual_model import PerceptualModel\n",
    "#from encoder.generator_model import Generator\n",
    "\n",
    "# Data Science Utils\n",
    "sys.path.append(os.path.join(os.pardir, 'data-science-learning'))\n",
    "\n",
    "from ds_utils import generative_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dir = Path.home() / 'Documents/generated_data/stylegan'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_DIR = Path(\"C:/Users/User/Documents/models/stylegan2\")\n",
    "MODEL_NAME = 'drawing2_1024'\n",
    "SNAPSHOT_NAME = 'network-snapshot-002048'\n",
    "\n",
    "Gs, Gs_kwargs, noise_vars = load_network(str(MODELS_DIR / MODEL_NAME / SNAPSHOT_NAME) + '.pkl')\n",
    "\n",
    "Z_SIZE = Gs.input_shape[1:][0]\n",
    "IMG_SIZE = Gs.output_shape[2:]\n",
    "IMG_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_images(images_dir, tfrecord_dir, data_dir, num_steps, num_snapshots, pure_projector=False,\n",
    "                  lr=0.1, dlatent_init_dir=None):\n",
    "    # setup projector\n",
    "    print('Setting up projector')\n",
    "    proj = projector.Projector(num_steps=num_steps, pure_projector=pure_projector, initial_learning_rate=lr)\n",
    "    proj.set_network(Gs)\n",
    "    \n",
    "    # generate tfrecords\n",
    "    images_paths = dataset_tool.create_from_images(str(tfrecord_dir), str(images_dir), False)\n",
    "    nb_images = len(images_paths)\n",
    "\n",
    "    # loading images from tfrecords\n",
    "    dataset_obj = training.dataset.load_dataset(data_dir=str(data_dir), tfrecord_dir=tfrecord_dir, \n",
    "                                                max_label_size=0, verbose=True, repeat=False, shuffle_mb=0)\n",
    "    assert dataset_obj.shape == Gs.output_shape[1:]\n",
    "    \n",
    "    # project all loaded images\n",
    "    print('=======================')\n",
    "    for image_idx in tqdm(range(nb_images)):\n",
    "        print(f'Projecting image {image_idx}/{nb_images}')\n",
    "        \n",
    "        images, _labels = dataset_obj.get_minibatch_np(1)\n",
    "        images = training.misc.adjust_dynamic_range(images, [0, 255], [-1, 1])\n",
    "        \n",
    "        # loading init dlatent, if given\n",
    "        if dlatent_init_dir is not None:\n",
    "            dlatent_init = np.load(dlatent_init_dir / (Path(images_paths[image_idx]).stem + '.npy'))\n",
    "        else:\n",
    "            dlatent_init = None\n",
    "        \n",
    "        run_path = data_dir / f'out_{image_idx}'\n",
    "        run_path.mkdir()\n",
    "        run_projector.project_image(proj, targets=images, \n",
    "                                    png_prefix=dnnlib.make_run_dir_path(str(run_path / 'image_')), \n",
    "                                    num_snapshots=num_snapshots,\n",
    "                                    dlatent_init=dlatent_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = res_dir / 'projection' / MODEL_NAME / SNAPSHOT_NAME / datetime.now().strftime(\"%Y%m%d_%H%M%S\") # where the projections results will be saved\n",
    "images_dir = Path.home() / 'Documents/generated_data/'\n",
    "\n",
    "tfrecord_dir = data_dir / 'tfrecords'\n",
    "project_images(images_dir=images_dir, tfrecord_dir=tfrecord_dir, data_dir=data_dir, \n",
    "               num_steps=1000, num_snapshots=10, pure_projector=False,\n",
    "               dlatent_init_dir=None)#data_dir.parent / 'latent_init')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_video(data_dir / 'out', res_dir / 'projection' / 'out_{}.mp4'.format(''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode\n",
    "This does not use the official StyleGAN v2 projector, but instead relies on the direct encoder setup used by the community for v1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from encoder.perceptual_model import PerceptualModel\n",
    "from encoder.generator_model import Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretrained_networks\n",
    "_G, _D, Gs = pretrained_networks.load_networks((str(MODELS_DIR / MODEL_NAME / SNAPSHOT_NAME) + '.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "PERCEPTUAL_MODEL_IMG_SIZE = 256\n",
    "\n",
    "# setup utils generator and perceptual model\n",
    "generator = Generator(Gs, BATCH_SIZE, randomize_noise=False)\n",
    "perceptual_model = PerceptualModel(PERCEPTUAL_MODEL_IMG_SIZE, layer=9, batch_size=BATCH_SIZE)\n",
    "perceptual_model.build_perceptual_model(generator, _D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_to_batches(l, n):\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_images(images_dir, data_dir, iterations, num_snapshots, learning_rate=1.):\n",
    "    # collect images\n",
    "    images_paths = [str(img) for img in images_dir.glob('*')][:3]\n",
    "    \n",
    "    run_path = data_dir\n",
    "    run_path.mkdir()\n",
    "    \n",
    "    snapshot_steps = set(iterations - np.linspace(0, iterations, num_snapshots, endpoint=False, dtype=int))\n",
    "    \n",
    "    # project all loaded images\n",
    "    for images_batch in tqdm(split_to_batches(images_paths, BATCH_SIZE), total=len(images_paths)//BATCH_SIZE):\n",
    "        cur_step = 0\n",
    "        images_names = [os.path.splitext(os.path.basename(img_path))[0] for img_path in images_batch]\n",
    "\n",
    "        perceptual_model.set_reference_images(images_batch)\n",
    "        optimizer = perceptual_model.optimize(generator.dlatent_variable, \n",
    "                                       iterations=iterations)\n",
    "        pbar = tqdm(optimizer, leave=False, mininterval=9, total=iterations)\n",
    "        for loss in pbar:\n",
    "            cur_step += 1\n",
    "            if cur_step in snapshot_steps:\n",
    "                #print(' '.join(images_names), ' loss:', loss)\n",
    "\n",
    "                # generate images from found dlatents and save them\n",
    "                generated_images = generator.generate_images()\n",
    "                generated_dlatents = generator.get_dlatents()\n",
    "                for img_array, dlatent, img_name in zip(generated_images, generated_dlatents, images_names):\n",
    "                    img = Image.fromarray(img_array, 'RGB')\n",
    "                    img.save(str(run_path / f'{cur_step}_{img_name}.png'), 'PNG')\n",
    "                    np.save(str(run_path / f'{cur_step}_{img_name}.npy'), dlatent)\n",
    "\n",
    "        generator.reset_dlatents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = res_dir / 'projection' / MODEL_NAME / SNAPSHOT_NAME / datetime.now().strftime(\"%Y%m%d_%H%M%S\") # where the projections results will be saved\n",
    "images_dir = Path.home() / 'Documents/generated_data/'\n",
    "\n",
    "encode_images(images_dir=images_dir, data_dir=data_dir, iterations=1000,  num_snapshots=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_latents = np.random.randn(18, Z_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = gen_image_fun(Gs, target_latents, Gs_kwargs, noise_vars, truncation_psi=0.5)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = synth_image_fun(Gs, target_latents[np.newaxis,:,:], Gs_kwargs, randomize_noise=True)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate some random samples and save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zlatents = np.random.randn(30, Z_SIZE)\n",
    "truncation_psi = 0.5\n",
    "\n",
    "data_dir = res_dir / 'projection' / MODEL_NAME / SNAPSHOT_NAME / 'rand_gen' / datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "data_dir.mkdir(parents=True, exist_ok=False)\n",
    "\n",
    "dlatents = map_latents(Gs, zlatents, truncation_psi)\n",
    "for i, dl in enumerate(dlatents):\n",
    "    img  = synth_image_fun(Gs, dl[np.newaxis,:,:], Gs_kwargs, randomize_noise=True)\n",
    "    img = Image.fromarray(img, 'RGB')\n",
    "    img.save(str(data_dir / f'{i}.png'), 'PNG')\n",
    "    np.save(str(data_dir / f'{i}.npy'), dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projected Latent Initialization\n",
    "Test network used to learn an initial mapping from an image to the intermediate StyleGAN latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = load_model(MODELS_DIR / MODEL_NAME / 'resnet' / 'finetuned_resnet.h5')\n",
    "resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_img_size = (512, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_img = Image.open(\"\")\n",
    "target_img = target_img.resize(resnet_img_size)\n",
    "plt.imshow(target_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_latent = resnet.predict(np.array(target_img)[np.newaxis,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = synth_image_fun(Gs, predicted_latent, Gs_kwargs, randomize_noise=True)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latent_init(resnet_path, images_dir, out_dir):\n",
    "    # setup projector\n",
    "    print('Setting up resnet model')\n",
    "    resnet = load_model(resnet_path)\n",
    "    resnet_img_size = (512, 512)\n",
    "    \n",
    "    # project all images\n",
    "    print('=======================')\n",
    "    all_images = list(images_dir.glob('*.png')) + list(images_dir.glob('*.jpg'))\n",
    "    for img_path in tqdm(all_images):\n",
    "        target_img = Image.open(str(img_path))\n",
    "        target_img = target_img.resize(resnet_img_size)\n",
    "        \n",
    "        predicted_latent = resnet.predict(np.array(target_img)[np.newaxis,:])[0]\n",
    "        \n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "        np.save(out_dir / (img_path.stem + '.npy'), predicted_latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_init_dir = res_dir / 'projection' / MODEL_NAME / SNAPSHOT_NAME / 'latent_init'\n",
    "images_dir = Path.home() / 'Documents/generated_data/'\n",
    "\n",
    "generate_latent_init(resnet_path=MODELS_DIR / MODEL_NAME / 'resnet' / 'finetuned_resnet.h5',\n",
    "               images_dir=images_dir, out_dir=latent_init_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load latents from other network and generate with current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dir = res_dir / 'projection' / 'original_ffhq' / 'stylegan2-ffhq-config-f'\n",
    "out_dir = res_dir / 'projection' / MODEL_NAME / SNAPSHOT_NAME / 'dlatent_mix' / datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "out_dir.mkdir(parents=True, exist_ok=False)\n",
    "\n",
    "for i, dl_path in enumerate(load_dir.glob('*.npy')):\n",
    "    dl = np.load(dl_path)\n",
    "\n",
    "    img = synth_image_fun(Gs, dl[np.newaxis,:,:], Gs_kwargs, randomize_noise=False)\n",
    "    other_img = imageio.imread(str(dl_path).replace('npy', 'png'))\n",
    "    \n",
    "    w = h = img.shape[0]\n",
    "    canvas = Image.new('RGBA', (w*2,h), 'white')\n",
    "    canvas.paste(Image.fromarray(img), (0, 0))\n",
    "    canvas.paste(Image.fromarray(other_img), (w, 0))\n",
    "    \n",
    "    canvas.save(str(out_dir / f'{i}.png'), 'PNG')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "StyleGAN",
   "language": "python",
   "name": "stylegan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "notify_time": "30",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "460.8px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
